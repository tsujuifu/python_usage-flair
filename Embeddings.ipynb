{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Flair - Embeddings</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import flair\n",
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Word Embeddings](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md)\n",
    "\n",
    "+ Glove\n",
    "+ FastText-Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The torch.Size([100])\n",
      "Token: 2 grass torch.Size([100])\n",
      "Token: 3 is torch.Size([100])\n",
      "Token: 4 green torch.Size([100])\n",
      "Token: 5 . torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "embedding = WordEmbeddings('glove')\n",
    "sentence = Sentence('The grass is green .')\n",
    "embedding.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token, token.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 我 torch.Size([300])\n",
      "Token: 2 喜歡 torch.Size([300])\n",
      "Token: 3 吃 torch.Size([300])\n",
      "Token: 4 水果 torch.Size([300])\n",
      "Token: 5 。 torch.Size([300])\n"
     ]
    }
   ],
   "source": [
    "embedding = WordEmbeddings('zh')\n",
    "sentence = Sentence('我 喜歡 吃 水果 。')\n",
    "embedding.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token, token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Flair Embeddings](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md)\n",
    "\n",
    "+ news-forward\n",
    "+ StackedEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import FlairEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The torch.Size([2048])\n",
      "Token: 2 grass torch.Size([2048])\n",
      "Token: 3 is torch.Size([2048])\n",
      "Token: 4 green torch.Size([2048])\n",
      "Token: 5 . torch.Size([2048])\n"
     ]
    }
   ],
   "source": [
    "embedding = FlairEmbeddings('news-forward')\n",
    "sentence = Sentence('The grass is green .')\n",
    "embedding.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token, token.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The torch.Size([4196])\n",
      "Token: 2 grass torch.Size([4196])\n",
      "Token: 3 is torch.Size([4196])\n",
      "Token: 4 green torch.Size([4196])\n",
      "Token: 5 . torch.Size([4196])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import StackedEmbeddings\n",
    "\n",
    "embedding = StackedEmbeddings([WordEmbeddings('glove'), FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward')])\n",
    "sentence = Sentence('The grass is green .')\n",
    "embedding.embed(sentence)\n",
    "\n",
    "for token in sentence:\n",
    "    print(token, token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ELMo Embeddings](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md)\n",
    "\n",
    "+ ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/yesray0216/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "embedding = ELMoEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/yesray0216/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The torch.Size([3072])\n",
      "Token: 2 grass torch.Size([3072])\n",
      "Token: 3 is torch.Size([3072])\n",
      "Token: 4 green torch.Size([3072])\n",
      "Token: 5 . torch.Size([3072])\n",
      "---------\n",
      "The , tensor([-0.3288,  0.2022, -0.5940,  ..., -1.2773,  0.3049,  0.2150])\n",
      "The , tensor([-0.3288,  0.2022, -0.5940,  ..., -1.4559,  0.2238,  0.1010])\n",
      "---------\n",
      "grass , tensor([ 0.2539, -0.2363,  0.5263,  ..., -0.7001,  0.8798,  1.4191])\n",
      "grava , tensor([ 0.0642, -0.4907,  0.7769,  ..., -0.7244,  1.9380, -0.5247])\n",
      "---------\n",
      "is , tensor([ 0.1915,  0.2300, -0.2894,  ..., -0.3626,  1.9066,  1.4520])\n",
      "is , tensor([ 0.1915,  0.2300, -0.2894,  ..., -0.3680,  1.9113,  1.4519])\n",
      "---------\n",
      "green , tensor([ 0.1779,  0.1309, -0.1041,  ..., -0.1006,  1.6152,  0.3299])\n",
      "green , tensor([ 0.1779,  0.1309, -0.1041,  ..., -0.1034,  1.6204,  0.3276])\n"
     ]
    }
   ],
   "source": [
    "sentence1 = Sentence('The grass is green .')\n",
    "sentence2 = Sentence('The grava is green .')\n",
    "\n",
    "embedding.embed(sentence1)\n",
    "embedding.embed(sentence2)\n",
    "\n",
    "for token in sentence1:\n",
    "    print(token, token.embedding.shape)\n",
    "\n",
    "print('---------')\n",
    "print(sentence1[0].text, ',', sentence1[0].embedding)\n",
    "print(sentence2[0].text, ',', sentence2[0].embedding)\n",
    "print('---------')\n",
    "print(sentence1[1].text, ',', sentence1[1].embedding)\n",
    "print(sentence2[1].text, ',', sentence2[1].embedding)\n",
    "print('---------')\n",
    "print(sentence1[2].text, ',', sentence1[2].embedding)\n",
    "print(sentence2[2].text, ',', sentence2[2].embedding)\n",
    "print('---------')\n",
    "print(sentence1[3].text, ',', sentence1[3].embedding)\n",
    "print(sentence2[3].text, ',', sentence2[3].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [BERT Embeddings](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_4_ELMO_BERT_FLAIR_EMBEDDING.md)\n",
    "\n",
    "+ English\n",
    "+ Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import BertEmbeddings\n",
    "\n",
    "embedding = BertEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The torch.Size([3072])\n",
      "Token: 2 grass torch.Size([3072])\n",
      "Token: 3 is torch.Size([3072])\n",
      "Token: 4 green torch.Size([3072])\n",
      "Token: 5 . torch.Size([3072])\n",
      "---------\n",
      "The , tensor([-0.0323, -0.3904, -1.1946,  ...,  0.1305, -0.1365, -0.4323])\n",
      "The , tensor([ 0.1527, -0.2964, -0.6643,  ...,  0.2863, -0.2772,  0.0180])\n",
      "---------\n",
      "grass , tensor([-0.3973,  0.2652, -0.1337,  ...,  0.3715,  0.1097, -1.1625])\n",
      "grava , tensor([ 0.3882, -0.4389, -0.0919,  ..., -0.2412,  0.5347,  0.5385])\n",
      "---------\n",
      "is , tensor([ 0.1374, -0.3688, -0.8292,  ...,  0.2533,  0.0294,  0.4293])\n",
      "is , tensor([ 0.4381, -0.4556, -0.3477,  ...,  0.7417,  0.1189,  0.7459])\n",
      "---------\n",
      "green , tensor([-0.7722, -0.1152,  0.3661,  ...,  0.1575, -0.0682, -0.7661])\n",
      "green , tensor([-0.4984, -0.4435,  0.3955,  ...,  0.7010, -0.0687, -0.0059])\n"
     ]
    }
   ],
   "source": [
    "sentence1 = Sentence('The grass is green .')\n",
    "sentence2 = Sentence('The grava is green .')\n",
    "\n",
    "embedding.embed(sentence1)\n",
    "embedding.embed(sentence2)\n",
    "\n",
    "for token in sentence1:\n",
    "    print(token, token.embedding.shape)\n",
    "\n",
    "print('---------')\n",
    "print(sentence1[0].text, ',', sentence1[0].embedding)\n",
    "print(sentence2[0].text, ',', sentence2[0].embedding)\n",
    "print('---------')\n",
    "print(sentence1[1].text, ',', sentence1[1].embedding)\n",
    "print(sentence2[1].text, ',', sentence2[1].embedding)\n",
    "print('---------')\n",
    "print(sentence1[2].text, ',', sentence1[2].embedding)\n",
    "print(sentence2[2].text, ',', sentence2[2].embedding)\n",
    "print('---------')\n",
    "print(sentence1[3].text, ',', sentence1[3].embedding)\n",
    "print(sentence2[3].text, ',', sentence2[3].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import BertEmbeddings\n",
    "\n",
    "embedding = BertEmbeddings('bert-base-chinese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 小明 torch.Size([3072])\n",
      "Token: 2 愛 torch.Size([3072])\n",
      "Token: 3 吃 torch.Size([3072])\n",
      "Token: 4 蘋果 torch.Size([3072])\n",
      "Token: 5 。 torch.Size([3072])\n",
      "---------\n",
      "小明 , tensor([ 0.3739, -0.7621, -0.3738,  ..., -0.3334, -0.0919,  0.2904])\n",
      "小明 , tensor([ 0.4984, -0.9325, -0.3565,  ..., -0.3877, -0.2532,  0.0981])\n",
      "---------\n",
      "愛 , tensor([ 0.5315, -0.0829, -1.0540,  ...,  0.8733,  0.4928,  0.8453])\n",
      "要 , tensor([ 0.2315, -0.0260, -0.8028,  ...,  0.7718,  0.2066,  0.3716])\n",
      "---------\n",
      "吃 , tensor([ 0.5125, -0.1900,  0.0707,  ...,  0.7921,  0.9561,  0.3185])\n",
      "吃 , tensor([ 0.2760, -0.2583, -0.6139,  ...,  0.7908,  0.3669,  0.1169])\n",
      "---------\n",
      "蘋果 , tensor([ 1.3542, -0.8648, -0.2211,  ...,  0.3679,  0.1687,  0.4705])\n",
      "蘋果 , tensor([ 1.1218, -0.6747, -0.2706,  ...,  0.2042, -0.3189,  0.6066])\n"
     ]
    }
   ],
   "source": [
    "sentence1 = Sentence('小明 愛 吃 蘋果 。')\n",
    "sentence2 = Sentence('小明 要 吃 蘋果 。')\n",
    "\n",
    "embedding.embed(sentence1)\n",
    "embedding.embed(sentence2)\n",
    "\n",
    "for token in sentence1:\n",
    "    print(token, token.embedding.shape)\n",
    "\n",
    "print('---------')\n",
    "print(sentence1[0].text, ',', sentence1[0].embedding)\n",
    "print(sentence2[0].text, ',', sentence2[0].embedding)\n",
    "print('---------')\n",
    "print(sentence1[1].text, ',', sentence1[1].embedding)\n",
    "print(sentence2[1].text, ',', sentence2[1].embedding)\n",
    "print('---------')\n",
    "print(sentence1[2].text, ',', sentence1[2].embedding)\n",
    "print(sentence2[2].text, ',', sentence2[2].embedding)\n",
    "print('---------')\n",
    "print(sentence1[3].text, ',', sentence1[3].embedding)\n",
    "print(sentence2[3].text, ',', sentence2[3].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Document Embeddings](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_5_DOCUMENT_EMBEDDINGS.md)\n",
    "\n",
    "+ DocumentPoolEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/yesray0216/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "\n",
    "embedding = DocumentPoolEmbeddings([WordEmbeddings('glove'), \n",
    "                                    FlairEmbeddings('news-forward'), FlairEmbeddings('news-backward'), \n",
    "                                    ELMoEmbeddings(), \n",
    "                                    BertEmbeddings()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4826,  0.3338,  0.3487,  ..., -0.4902,  0.9246,  0.6966])\n",
      "tensor([-0.2953,  0.0270,  0.3005,  ..., -0.5320,  1.1212,  0.2834])\n",
      "---------\n",
      "torch.Size([10340])\n",
      "torch.Size([10340])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/yesray0216/anaconda3/lib/python3.6/site-packages/allennlp/nn/util.py:150: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    }
   ],
   "source": [
    "sentence1 = Sentence('The grass is green .')\n",
    "sentence2 = Sentence('The grava is green .')\n",
    "\n",
    "embedding.embed(sentence1)\n",
    "embedding.embed(sentence2)\n",
    "\n",
    "print(sentence1.get_embedding())\n",
    "print(sentence2.get_embedding())\n",
    "print('---------')\n",
    "print(sentence1.get_embedding().shape)\n",
    "print(sentence2.get_embedding().shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
